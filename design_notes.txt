// Other things that we need are a software algorithm to convert a matrix into the CISR format


// Memory Handler for the Sparse Matrix and Converter to the CISR Format 

/*
Things needed:
- Data line width (how long do we want the words/do we want to fetch multiple words at a time)
- Do we need a buffer or is this handled on the NOC side 
- There are two components that will be accessing the memory
    - The Sparse Matrix Loader 
    - The vector loader 

- Cache line is 64 bytes (8) 64 bit words 

- Ensure that the fetches are cache aligned otherwise the algorithm wouldn't work (requires that the matrices are aligned)
- Or you design the architecture such that if you miss on the some of the values in the cache line (ie a memory call returns less values then expected you can still align the fetch later)

- Do we want to use a large section of the RAM to store the vector instead of doing the crossbar 
- What access structure do we need if we are parallelizing the result 

- Need a physical memory address (Does this mean we need access to the memory virtualization process?)
- Or can we assume that the processor sends us the correct memory address? 


We can define the integer word size in C++ everything is assumed to be 64 bits and just broken up into smaller word sizes 


Vector Loads Independent (Spatially Local expect first cache miss and then multiple cache hits (Large Cache Words in the L2)) -> 

5 Commands recieved from the processor:
- Sparse Matrix Value Vector (Address pointer)
- Sparse Matrix Row Length (CISR) pointer 
- Sparse Matrix Vector Channel ID pointer 
- Sparse Matrix Vector Column Index pointer
- Multiplication Vector


Memory Request Backup in the Queue 
1. Assume that we are going to miss on one of the cache lines for the matrix (They are all stored locally)
2. Want another transaction ID for the next round of values stored in the CISR format (Or we can just wait for the original transaction ID to come back and stall)


*/

// Parallelized Computation Channels 

/*
We need to load the values from the sparse matrix memory into an arbriter struture that directs the vectors into whichever channel they should be in

- Things to note 
  - Need to know the memory offset for the matrixes in the physical memory address space

- We will have 4 channels starting out. (Depending on the cache line length and the number word)

4 channel ID's that the rows for the CISR will get converted for 
- Each channel has its own fifo involving an ID 


*/

// Pipeline Diagram Rough 


/*

Use buffers to segment the pipeline stages

Single Stage: (Wait until complete)
1. Load Input Vector 

Computational Pipeline: 

1. Fetch CISR Matrix element (Segemented into 4 data lines) have to wait until all three arrive (stall)
 - Value (Trans id 1)
 - Column Indice (Trans id 2)
 - Row Length (Trans id 3)

This fetch needs to be queued so that we can continuously pull the values 

2. Arbiter figures which channel to forward the values to depending on which channel is available

3. Channel Calculation (Mul 0)
 - Read the vector and forward to the appropiate channel 
 - Start Multiplication 

4. (Mul 1) // at some point insert a row id to the element to tell the accumulator which row the calculation belongs to 
5. (Mul 2) 
6. (Mul 3)

7. Move into accumulator (Sums for each row) Max # of sums being kept track of equivalent to number of channels
  - Multiple channels each keeping track of the row id conversion done inside the channel fifo
*/

/*
First in idle state.

1. Send command initialize SPMV with the SPM matrix pointer 

2. Send the number of rows and the number of non-zero elements in the SPM (To separate steps in the initialize process)
3. Send the pointer to the vector and the lenght of the vector 


4. Begin the vector prefetching before the pipeline (Cannot begin until clock cycle after recieving the pointer to the vector and the lenght)

5. Enter the pipeline 
*/





//////////////////////////////////////////////////////////////////////////////////////////////////////////
// Handling the Memory Operations
//////////////////////////////////////////////////////////////////////////////////////////////////////////

Two separate modules: 

        1. For the Vector Fetching (Multiple Ports dictated by the number of channels available for the parallel processing)
        2. For the SPM Fetching of the elements
    

1. Vector Fetching Module Requirements:
        a. Memory Fetch Take control of the NoC1 Interface
            Signals for Control (Multiplex signal lines feeding into the mem fetch) something like vec_fetch 
        b. Monitor the NoC2 Transaction ID's for the appropiate return 

        Utilizes a Return Buffer (Filled by transaction receipts) (Max 64) 
        - Don't want to handle loop around case 
        
        Vector entries are assumed 32-bit integers ( 4 bytes )
        Cache Line is 64 bytes ( Max allowable )

        16 vector components per line 

        Max Length of Vector Absolute is 16*64 = 1024 (Reduce the lenght size)


        Transaction ID table (Fast Lookup)
        -  Allocate into the Transaction ID table the corresponding registers (Max 16 registers for each memory request from cache line)
        -  Fill into those registers (How do we multiplex those registers?) File values to the corresponding registers (Can't assume equal access times)
        -  Line for the registers 
        -  Registers ordered from left to right 
        -  Calculate the Cache Line Offset for Register Offset per Transaction 

        A 32-bit integer is aligned by 0x04 = 0b00000100. Since it has 4 bytes

        The cache line is aligned to 0b01000000 = 0x40. 

        Lets say I have a physical vector address ending a byte, 0x70 = 0b01110000 the lower two bits are offsets in the cache line determined by 0b0011.

        So we start the register count offset at 3. 

        So we retrieve the first cache line off of 0b01000000 = 0x0400 and we offset the register addressing in the transaction table by 3. 

        On that first retrieval we also have to offset grabbing the values from the cacheline. 

                We know that the register offset is 3, so we do 3*4 bytes as the offset in the first cache line. [63:3*4]. We know the transaction ID is sequential for the vector. 
                Use as index to the a block of registers. 
                
                16 Registers per cache line.

                multiplex 16 different registers 

                Register file with all of the data stored. 

                16 lines - divide up the cache line return

                Check trans_id == 0, use the offset to start where the cache line is returned 

        Looks like below for offset = 2

        data[0] = cache_line[31:0];
        data[1] = cache_line[63:32];
        data[2] = cache_line[95:64];
        data[3] = cache_line[127:96];

        if (trans_id == 0) begin
            reg_file[trans_id] = data[offset]
            reg_file[trans_id+1] = data[offset+1] // Stop at offset + i == num of components in cacheline
        end
        else begin
            reg_file[offset*trans_id]
        end
 
        We need a request and a response handler based off of the table.
                - When a valid response is recieved check the id and grab registers from that transaction
                - For the request, we just are pushing a request every single cycle for the prefetch routine
        

        



